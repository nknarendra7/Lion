{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTensorFlow is based on graph based computation.It’s an alternative way of conceptualising mathematical calculations.\\nConsider the following expression a = (b+c)* (c+2).\\nWe can break this function down into the following components:\\n\\td = b+c\\n\\te = c+2\\n\\ta = d*e\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensorflow basic command\n",
    "#TensorFlow is based on graph based computation.It’s an alternative way of conceptualising mathematical calculations.\n",
    "#Consider the following expression a = (b+c)* (c+2).\n",
    "#We can break this function down into the following components:\n",
    "'''\n",
    "d = b+c\n",
    "e = c+2\n",
    "a = d*e\n",
    "\n",
    "'''"
   ]
  },
  {
   "attachments": {
    "Simple-graph-example.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Simple-graph-example.png](attachment:Simple-graph-example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Let’s first make TensorFlow perform our little example calculation above.\n",
    "import tensorflow as tf\n",
    "# first, create a TensorFlow constant\n",
    "const = tf.constant(2.0, name=\"const\")\n",
    "    \n",
    "# create TensorFlow variables\n",
    "b = tf.Variable(2.0, name='b')\n",
    "c = tf.Variable(1.0, name='c')\n",
    "# now create some operations\n",
    "d = tf.add(b, c, name='d')\n",
    "e = tf.add(c, const, name='e')\n",
    "a = tf.multiply(d, e, name='a')\n",
    "\n",
    "#The next step is to setup an object to initialise the variables and the graph structure\n",
    "# setup the variable initialisation\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "#To run the operations between the variables, we need to start a TensorFlow session – tf.Session.\n",
    "#The TensorFlow session is an object where all operations are run. TensorFlow was initially created in a static graph paradigm – in other words, first \n",
    "#all the operations and variables are defined (the graph structure) and then these are compiled within the tf.Session object.\n",
    "#There is now the option to build graphs on the fly using the TensorFlow Eager framework.\n",
    "#However, there are still advantages in building static graphs using the tf.Session object.\n",
    "# start the session\n",
    "with tf.Session() as sess:\n",
    "    # initialise the variables\n",
    "    sess.run(init_op)\n",
    "    # compute the output of the graph\n",
    "    a_out = sess.run(a)\n",
    "    print(\"Variable a is {}\".format(a_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow placeholder\n",
    "#Let’s also say that we didn’t know what the value of the array b would be during the declaration phase of the TensorFlow problem.\n",
    "# In this case, TensorFlow requires us to declare the basic structure of the data by using the tf.placeholder variable declaration.\n",
    "#Let’s use it for b:\n",
    "# create TensorFlow variables\n",
    "b = tf.placeholder(tf.float32, [None, 1], name='b')\n",
    "\n",
    "#Because we aren’t providing an initialisation in this declaration, we need to tell TensorFlow what data type each element within the tensor is going to be.\n",
    "#In this case, we want to use tf.float32.\n",
    "#The second argument is the shape of the data that will be “injected” into this variable.  In this case, we want to use a (? x 1) sized array\n",
    "#the placeholder is willing to accept a None argument in the size declaration.  Now we can inject as much 1-dimensional data that we want into the b variable.\n",
    "#The only other change we need to make to our program is in the sess.run(a,…) command:\n",
    "a_out = sess.run(a, feed_dict={b: np.arange(0, 10)[:, np.newaxis]})\n",
    "#As suggested by the argument name, feed_dict, the input to be supplied is a Python dictionary, with each key being the name of the placeholder that we are filling.\n",
    "\n",
    "#Simple three layer neural network\n",
    "#This MNIST dataset is a set of 28×28 pixel grayscale images which represent hand-written digits.  It has 55,000 training rows, 10,000 testing rows and 5,000 validation rows.\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "#The one_hot=True argument specifies that instead of the labels associated with each image being the \n",
    "#digit itself i.e. “4”, it is a vector with “one hot” node and all the other nodes being zero i.e. [0, 0, 0, 0, 1, 0, 0, 0, 0, 0].  This lets us easily feed it into the output layer of our neural network.\n",
    "# Python optimisation variables\n",
    "learning_rate = 0.5\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "# declare the training data placeholders\n",
    "# input x - for 28 x 28 pixels = 784\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "# now declare the output data placeholder - 10 digits\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#Notice the x input layer is 784 nodes corresponding to the 28 x 28 (=784) pixels, and the y output layer is 10 nodes corresponding to the 10 possible digits.\n",
    "# the size of x is (? x 784), where the ? stands for an as yet unspecified number of samples to be input – this is the function of the placeholder variable.\n",
    "#Now we need to setup the weight and bias variables for the three layer neural network.  \n",
    "#There are always L-1 number of weights/bias tensors, where L is the number of layers.  So in this case, we need to setup two tensors for each:\n",
    "# now declare the weights connecting the input to the hidden layer\n",
    "W1 = tf.Variable(tf.random_normal([784, 300], stddev=0.03), name='W1')\n",
    "b1 = tf.Variable(tf.random_normal([300]), name='b1')\n",
    "# and the weights connecting the hidden layer to the output layer\n",
    "W2 = tf.Variable(tf.random_normal([300, 10], stddev=0.03), name='W2')\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='b2')\n",
    "\n",
    "#First, we declare some variables for W1 and b1, the weights and bias for the connections between the input and hidden layer.\n",
    "#This neural network will have 300 nodes in the hidden layer, so the size of the weight tensor W1 is [784, 300].\n",
    "# We initialise the values of the weights using a random normal distribution with a mean of zero and a standard deviation of 0.03.\n",
    "#Likewise, we create W2 and b2 variables to connect the hidden layer to the output layer of the neural network.\n",
    "#Next, we have to setup node inputs and activation functions of the hidden layer nodes:\n",
    "\n",
    "\n",
    "# calculate the output of the hidden layer\n",
    "hidden_out = tf.add(tf.matmul(x, W1), b1)\n",
    "hidden_out = tf.nn.relu(hidden_out)\n",
    "\n",
    "#Now, let’s setup the output layer, y_:\n",
    "# now calculate the hidden layer output - in this case, let's use a softmax activated\n",
    "# output layer\n",
    "y_ = tf.nn.softmax(tf.add(tf.matmul(hidden_out, W2), b2))\n",
    "\n",
    "#We also have to include a cost or loss function for the optimisation / backpropagation to work on.\n",
    "y_clipped = tf.clip_by_value(y_, 1e-10, 0.9999999)\n",
    "cross_entropy = -tf.reduce_mean(tf.reduce_sum(y * tf.log(y_clipped)\n",
    "                         + (1 - y) * tf.log(1 - y_clipped), axis=1))\n",
    "# The first line is an operation converting the output y_ to a clipped version, limited between 1e-10 to 0.999999. \n",
    "# This is to make sure that we never get a case were we have a log(0) operation occurring during training\n",
    "#this would return NaN and break the training process.  The second line is the cross entropy calculation.\n",
    "#To perform this calculation, first we use TensorFlow’s tf.reduce_sum function – this function basically takes the sum of a given axis of the tensor you supply.\n",
    "#In this case, the tensor that is supplied is the element-wise cross-entropy calculation for a single node and training sample\n",
    "# Remember that y and y_clipped in the above calculation are (m x 10) tensors – therefore we need to perform the first sum over the second axis.  This is specified\n",
    "#using the axis=1 argument, where “1” actually refers to the second axis when we have a zero-based indices system like Python.\n",
    "# add an optimiser\n",
    "optimiser = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
    "# finally setup the initialisation operator\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# define an accuracy assessment operation\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#Setting up the training\n",
    "# start the session\n",
    "with tf.Session() as sess:\n",
    "   # initialise the variables\n",
    "   sess.run(init_op)\n",
    "   total_batch = int(len(mnist.train.labels) / batch_size)\n",
    "   for epoch in range(epochs):\n",
    "        avg_cost = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size=batch_size)\n",
    "             _, c = sess.run([optimiser, cross_entropy], \n",
    "                         feed_dict={x: batch_x, y: batch_y})\n",
    "            avg_cost += c / total_batch\n",
    "        print(\"Epoch:\", (epoch + 1), \"cost =\", \"{:.3f}\".format(avg_cost))\n",
    "   print(sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
    "#Have fun explore more\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
